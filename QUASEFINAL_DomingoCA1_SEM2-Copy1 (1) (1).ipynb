{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f467566",
   "metadata": {},
   "source": [
    "## Dataset: Maternal Health Risk\n",
    "\n",
    "### Licence of use\n",
    "\n",
    "- That dataset was collected from UCI Machine Learning Repository -https://archive.ics.uci.edu/dataset/863/maternal+health+risk\n",
    "\n",
    "- licence by Creative Commons Attribution 4.0 (CC BY 4.0) https://creativecommons.org/licenses/by/4.0/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b66311",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "\n",
    "- The Data has been collected from different hospitals, community clinics, maternal health cares from the rural areas of Bangladesh through the IoT based risk monitoring system.\n",
    "\n",
    "###  Attributes Description:\n",
    "\n",
    "- Age - Age in years when a woman is pregnant\n",
    "- SystolicBP - Upper value of Blood Pressure in mmHg\n",
    "- DiastolicBP - Lower value of Blood Pressure in mmHg\n",
    "- BS - Blood glucose levels is in terms of a molar concentration, mmol/L\n",
    "- BodyTemp - Body temperature in Fahrenheit\n",
    "- HeartRate - Resting heart rate in beats per minute\n",
    "- RiskLevel - Predicted Risk Intensity Level during pregnancy ['high risk', 'mid risk', 'low risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67ca7143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437af6e6",
   "metadata": {},
   "source": [
    "# 2. Data Understanding Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487ee3f",
   "metadata": {},
   "source": [
    "### Practical Big Data (PySparkSQL) - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c999a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due the different version of python can be found and each machine or libriries \n",
    "# Avoid warnigs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b332beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PySparkSQL\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Análise de Dados de Saúde Materna\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "427c2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "csv_file = \"/user/user1/Maternal_Health_Risk.csv\"\n",
    "\n",
    "# Read and create a temporary view\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(csv_file)\n",
    "df.createOrReplaceTempView(\"rawdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7863afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SystolicBP: integer (nullable = true)\n",
      " |-- DiastolicBP: integer (nullable = true)\n",
      " |-- BS: double (nullable = true)\n",
      " |-- BodyTemp: double (nullable = true)\n",
      " |-- HeartRate: integer (nullable = true)\n",
      " |-- RiskLevel: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualise inferred schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d93114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+----+--------+---------+---------+\n",
      "|Age|SystolicBP|DiastolicBP|  BS|BodyTemp|HeartRate|RiskLevel|\n",
      "+---+----------+-----------+----+--------+---------+---------+\n",
      "| 25|       130|         80|15.0|    98.0|       86|high risk|\n",
      "| 35|       140|         90|13.0|    98.0|       70|high risk|\n",
      "| 29|        90|         70| 8.0|   100.0|       80|high risk|\n",
      "| 30|       140|         85| 7.0|    98.0|       70|high risk|\n",
      "| 35|       120|         60| 6.1|    98.0|       76| low risk|\n",
      "| 23|       140|         80|7.01|    98.0|       70|high risk|\n",
      "| 23|       130|         70|7.01|    98.0|       78| mid risk|\n",
      "| 35|        85|         60|11.0|   102.0|       86|high risk|\n",
      "| 32|       120|         90| 6.9|    98.0|       70| mid risk|\n",
      "| 42|       130|         80|18.0|    98.0|       70|high risk|\n",
      "+---+----------+-----------+----+--------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Execute an SQL query to select the first 10 rows from the temporary view\n",
    "data = spark.sql(\"SELECT * FROM rawdata LIMIT 10\")\n",
    "\n",
    "# Directly display the query results\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c94ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|TotalRows|\n",
      "+---------+\n",
      "|     1014|\n",
      "+---------+\n",
      "\n",
      "Number of Columns: 7\n"
     ]
    }
   ],
   "source": [
    "# Count rows\n",
    "num_rows = spark.sql(\"SELECT COUNT(*) as TotalRows FROM rawdata\").show()\n",
    "\n",
    "# Count columns using the PySpark DataFrame (not directly SQL)\n",
    "num_columns = len(df.columns)\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989f4ee",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6e29e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+---+--------+---------+---------+\n",
      "|Age|SystolicBP|DiastolicBP| BS|BodyTemp|HeartRate|RiskLevel|\n",
      "+---+----------+-----------+---+--------+---------+---------+\n",
      "|  0|         0|          0|  0|       0|        0|        0|\n",
      "+---+----------+-----------+---+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when\n",
    "\n",
    "# Listing the number of missing values per column\n",
    "df.select([_sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56e05145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RiskLevel  Count\n",
      "0   low risk    406\n",
      "1   mid risk    336\n",
      "2  high risk    272\n"
     ]
    }
   ],
   "source": [
    "# Collecting data for visualization\n",
    "risk_level_distribution = spark.sql(\"SELECT RiskLevel, COUNT(*) as Count FROM rawdata GROUP BY RiskLevel\").toPandas()\n",
    "\n",
    "# Check the collected data\n",
    "print(risk_level_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c35e6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of Risk Levels with counts above bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(risk_level_distribution['RiskLevel'], risk_level_distribution['Count'], color=['skyblue', 'lightgreen', 'salmon'])\n",
    "\n",
    "# Adding counts above bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, yval, ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of Risk Levels')\n",
    "plt.xlabel('Risk Level')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0cb65",
   "metadata": {},
   "source": [
    "### Comparative bar chart for average Systolic and Diastolic blood pressure, by Risk Level level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96436cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Determining the associations between the average systolic and diastolic blood pressures (SystolicBP and DiastolicBP, respectively) and the RiskLevel.\n",
    "pressure_risk = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    RiskLevel, \n",
    "    AVG(SystolicBP) AS AvgSystolicBP, \n",
    "    AVG(DiastolicBP) AS AvgDiastolicBP \n",
    "FROM rawdata \n",
    "GROUP BY RiskLevel\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e4fd2",
   "metadata": {},
   "source": [
    "- The purpose of the query is to evaluate the data with an emphasis on determining the associations between the average systolic and diastolic blood pressures SystolicBP and DiastolicBP, respectively and the RiskLevel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abd1b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Bar width\n",
    "barWidth = 0.50\n",
    "\n",
    "# Setting the position of the bars\n",
    "r1 = np.arange(len(pressure_risk['RiskLevel']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Creating the bars\n",
    "plt.bar(r1, pressure_risk['AvgSystolicBP'], color='blue', width=barWidth, edgecolor='grey', label='Systolic')\n",
    "plt.bar(r2, pressure_risk['AvgDiastolicBP'], color='red', width=barWidth, edgecolor='grey', label='Diastolic')\n",
    "\n",
    "# Adding labels to the bars\n",
    "plt.xlabel('Risk Level', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(pressure_risk['RiskLevel']))], pressure_risk['RiskLevel'])\n",
    "\n",
    "# Creating the legend and showing the plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fa0eb",
   "metadata": {},
   "source": [
    "Este código primeiro configura o ambiente de plotagem determinando a largura das barras e a posição delas no gráfico. Depois, plota duas séries de dados: uma para a pressão sistólica média e outra para a diastólica média, cada uma associada a um nível de risco diferente. A legenda e os rótulos dos eixos ajudam a tornar o gráfico mais legível.\n",
    "\n",
    "Esse gráfico proporcionará uma visualização clara das diferenças nas médias de pressão sistólica e diastólica entre os diferentes níveis de risco. Se precisar de mais ajuda ou tiver outras perguntas, estou aqui!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b4372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0f1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "age_risk = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    RiskLevel, \n",
    "    AVG(Age) AS AvgAge \n",
    "FROM rawdata \n",
    "GROUP BY RiskLevel\n",
    "ORDER BY CASE \n",
    "    WHEN RiskLevel = 'low risk' THEN 1\n",
    "    WHEN RiskLevel = 'mid risk' THEN 2\n",
    "    WHEN RiskLevel = 'high risk' THEN 3\n",
    "    ELSE 4\n",
    "END\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebf5f0",
   "metadata": {},
   "source": [
    "- By analyzing how the average age varies between different risk levels, through this analysis it is possible to identify age-related patterns or trends that may be relevant to understanding risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd18a8",
   "metadata": {},
   "source": [
    "### Average Age by Risk Level chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a278412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Adjusting color_mapping to match the exact strings from the SQL query\n",
    "color_mapping = {\n",
    "    'high risk': 'red',    # Matching 'high risk' to red\n",
    "    'mid risk': 'yellow',  # Matching 'mid risk' to yellow\n",
    "    'low risk': 'green'    # Matching 'low risk' to green\n",
    "}\n",
    "\n",
    "# Applying the color mapping to generate a list of colors for each bar\n",
    "# This assumes age_risk['RiskLevel'] contains 'low risk', 'mid risk', 'high risk'\n",
    "bar_colors = [color_mapping[risk_level] for risk_level in age_risk['RiskLevel']]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(age_risk['RiskLevel'], age_risk['AvgAge'], color=bar_colors)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Average Age by Risk Level')\n",
    "plt.xlabel('Risk Level')\n",
    "plt.ylabel('Average Age')\n",
    "plt.xticks(rotation=45)  # Rotating X-axis labels for better readability\n",
    "\n",
    "# Displaying the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101cbac",
   "metadata": {},
   "source": [
    "- This chart provides a clear visualization of how the average age varies between different risk levels. This can help identify whether there is an age trend associated with risk level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20e354",
   "metadata": {},
   "source": [
    "# Modeling Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d055e",
   "metadata": {},
   "source": [
    "##  Neural Network For Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c662481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Determine the number of input features\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# If RiskLevel is binary, use 1 output neuron with sigmoid, otherwise adjust for multiclass\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' and adjust the number of neurons if it's multiclass\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Adjust as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe8e9d",
   "metadata": {},
   "source": [
    "- Import Libraries: Imports TensorFlow and specific modules for creating models (Sequential) and layers (Dense).\n",
    "\n",
    "- Determine Number of Input Features: Sets n_features to the number of columns in X_train_scaled, excluding the target variable. This tells the model how many inputs each data point has.\n",
    "\n",
    "- Create Sequential Model:\n",
    "\n",
    "- A Sequential model is a linear stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "- The Dense layer is a fully connected layer, meaning each neuron in the layer receives input from all neurons of the previous layer.\n",
    "The first Dense layer specifies input_shape=(n_features,), which defines the shape of the input data.\n",
    "relu (Rectified Linear Unit) is used as the activation function for hidden layers to introduce non-linearity, helping the network learn complex patterns.\n",
    "Output Layer:\n",
    "\n",
    "For binary classification (two classes), the output layer has 1 neuron and uses the sigmoid activation function, which outputs a probability (0 to 1) indicating class membership.\n",
    "For multiclass classification, you would use the softmax activation function and adjust the number of neurons to match the number of classes.\n",
    "Compile the Model:\n",
    "\n",
    "The model is compiled with the adam optimizer, a popular choice that adjusts the learning rate dynamically.\n",
    "binary_crossentropy is used as the loss function for binary classification, which is suitable for binary labels.\n",
    "Metrics: accuracy is used to evaluate the performance of the model during training and testing.\n",
    "Purpose\n",
    "This code sets up a neural network for binary classification, preparing it for training with your dataset. The model learns to predict the binary RiskLevel based on input features. After training, it can classify new, unseen data points into one of the two categories based on the learned patterns.\n",
    "\n",
    "This process is crucial for tasks where you need to categorize inputs into two groups, such as predicting whether a condition is present (risk) or not based on various indicators (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59ed2cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.2801 - loss: 0.7380 - val_accuracy: 0.2761 - val_loss: 0.6974\n",
      "Epoch 2/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3763 - loss: 0.6641 - val_accuracy: 0.3926 - val_loss: 0.6259\n",
      "Epoch 3/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4805 - loss: 0.6103 - val_accuracy: 0.4356 - val_loss: 0.5581\n",
      "Epoch 4/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4771 - loss: 0.5379 - val_accuracy: 0.4540 - val_loss: 0.4842\n",
      "Epoch 5/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5449 - loss: 0.4840 - val_accuracy: 0.4601 - val_loss: 0.3993\n",
      "Epoch 6/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5283 - loss: 0.4276 - val_accuracy: 0.4601 - val_loss: 0.3055\n",
      "Epoch 7/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5232 - loss: 0.3548 - val_accuracy: 0.4601 - val_loss: 0.2054\n",
      "Epoch 8/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5335 - loss: 0.2721 - val_accuracy: 0.4601 - val_loss: 0.0947\n",
      "Epoch 9/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5247 - loss: 0.1798 - val_accuracy: 0.4847 - val_loss: -0.0205\n",
      "Epoch 10/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5162 - loss: 0.0470 - val_accuracy: 0.4969 - val_loss: -0.1361\n",
      "Epoch 11/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5714 - loss: -0.0304 - val_accuracy: 0.4969 - val_loss: -0.2617\n",
      "Epoch 12/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5138 - loss: -0.1573 - val_accuracy: 0.5092 - val_loss: -0.3926\n",
      "Epoch 13/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5218 - loss: -0.2024 - val_accuracy: 0.5092 - val_loss: -0.5307\n",
      "Epoch 14/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5102 - loss: -0.2680 - val_accuracy: 0.5153 - val_loss: -0.6736\n",
      "Epoch 15/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5280 - loss: -0.5064 - val_accuracy: 0.5153 - val_loss: -0.8426\n",
      "Epoch 16/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5696 - loss: -0.3444 - val_accuracy: 0.5153 - val_loss: -0.9970\n",
      "Epoch 17/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5440 - loss: -0.6859 - val_accuracy: 0.5153 - val_loss: -1.1857\n",
      "Epoch 18/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5422 - loss: -0.7013 - val_accuracy: 0.5153 - val_loss: -1.3810\n",
      "Epoch 19/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: -0.9260 - val_accuracy: 0.5153 - val_loss: -1.6116\n",
      "Epoch 20/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5356 - loss: -1.0497 - val_accuracy: 0.5215 - val_loss: -1.8576\n",
      "Epoch 21/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5530 - loss: -1.0894 - val_accuracy: 0.5215 - val_loss: -2.1184\n",
      "Epoch 22/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5521 - loss: -1.3605 - val_accuracy: 0.5276 - val_loss: -2.4263\n",
      "Epoch 23/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5087 - loss: -1.5559 - val_accuracy: 0.5276 - val_loss: -2.7552\n",
      "Epoch 24/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5220 - loss: -1.7417 - val_accuracy: 0.5276 - val_loss: -3.1187\n",
      "Epoch 25/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5276 - loss: -2.2896 - val_accuracy: 0.5276 - val_loss: -3.5351\n",
      "Epoch 26/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5296 - loss: -2.3236 - val_accuracy: 0.5276 - val_loss: -3.9571\n",
      "Epoch 27/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: -2.9314 - val_accuracy: 0.5276 - val_loss: -4.5063\n",
      "Epoch 28/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5457 - loss: -3.2489 - val_accuracy: 0.5276 - val_loss: -5.0225\n",
      "Epoch 29/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5652 - loss: -3.1395 - val_accuracy: 0.5276 - val_loss: -5.5989\n",
      "Epoch 30/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5403 - loss: -4.2436 - val_accuracy: 0.5276 - val_loss: -6.2790\n",
      "Epoch 31/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5391 - loss: -5.1257 - val_accuracy: 0.5276 - val_loss: -6.9530\n",
      "Epoch 32/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5554 - loss: -4.2478 - val_accuracy: 0.5276 - val_loss: -7.6828\n",
      "Epoch 33/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5394 - loss: -5.0548 - val_accuracy: 0.5276 - val_loss: -8.5308\n",
      "Epoch 34/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5492 - loss: -5.6395 - val_accuracy: 0.5276 - val_loss: -9.3505\n",
      "Epoch 35/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5789 - loss: -5.6118 - val_accuracy: 0.5276 - val_loss: -10.2464\n",
      "Epoch 36/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5674 - loss: -7.8883 - val_accuracy: 0.5276 - val_loss: -11.2464\n",
      "Epoch 37/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5560 - loss: -7.3009 - val_accuracy: 0.5276 - val_loss: -12.2414\n",
      "Epoch 38/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5649 - loss: -8.5293 - val_accuracy: 0.5276 - val_loss: -13.3822\n",
      "Epoch 39/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5579 - loss: -9.8892 - val_accuracy: 0.5276 - val_loss: -14.5604\n",
      "Epoch 40/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5759 - loss: -10.2987 - val_accuracy: 0.5276 - val_loss: -15.9075\n",
      "Epoch 41/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5440 - loss: -12.2609 - val_accuracy: 0.5276 - val_loss: -17.2569\n",
      "Epoch 42/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5332 - loss: -11.5927 - val_accuracy: 0.5276 - val_loss: -18.5574\n",
      "Epoch 43/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5534 - loss: -13.6844 - val_accuracy: 0.5276 - val_loss: -19.9774\n",
      "Epoch 44/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5659 - loss: -11.9083 - val_accuracy: 0.5276 - val_loss: -21.4318\n",
      "Epoch 45/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5636 - loss: -13.2341 - val_accuracy: 0.5276 - val_loss: -23.0459\n",
      "Epoch 46/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5664 - loss: -14.9497 - val_accuracy: 0.5276 - val_loss: -24.7698\n",
      "Epoch 47/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5764 - loss: -18.2932 - val_accuracy: 0.5276 - val_loss: -26.5474\n",
      "Epoch 48/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5384 - loss: -20.1222 - val_accuracy: 0.5276 - val_loss: -28.4117\n",
      "Epoch 49/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5577 - loss: -20.4640 - val_accuracy: 0.5276 - val_loss: -30.3499\n",
      "Epoch 50/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5711 - loss: -20.1348 - val_accuracy: 0.5276 - val_loss: -32.2498\n",
      "Epoch 51/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5429 - loss: -25.0490 - val_accuracy: 0.5276 - val_loss: -34.3984\n",
      "Epoch 52/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: -23.3423 - val_accuracy: 0.5276 - val_loss: -36.4347\n",
      "Epoch 53/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5609 - loss: -24.1451 - val_accuracy: 0.5276 - val_loss: -38.5916\n",
      "Epoch 54/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5489 - loss: -26.2393 - val_accuracy: 0.5276 - val_loss: -41.0367\n",
      "Epoch 55/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5616 - loss: -28.9939 - val_accuracy: 0.5276 - val_loss: -43.5979\n",
      "Epoch 56/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5505 - loss: -31.4222 - val_accuracy: 0.5276 - val_loss: -46.1662\n",
      "Epoch 57/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5502 - loss: -34.0583 - val_accuracy: 0.5276 - val_loss: -48.8697\n",
      "Epoch 58/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5355 - loss: -32.8548 - val_accuracy: 0.5276 - val_loss: -51.7362\n",
      "Epoch 59/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5691 - loss: -34.7076 - val_accuracy: 0.5276 - val_loss: -54.6045\n",
      "Epoch 60/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: -36.2710 - val_accuracy: 0.5276 - val_loss: -57.7738\n",
      "Epoch 61/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5660 - loss: -37.6094 - val_accuracy: 0.5276 - val_loss: -60.8829\n",
      "Epoch 62/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5753 - loss: -40.7172 - val_accuracy: 0.5276 - val_loss: -64.0914\n",
      "Epoch 63/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5810 - loss: -45.0047 - val_accuracy: 0.5276 - val_loss: -67.3959\n",
      "Epoch 64/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5693 - loss: -45.2128 - val_accuracy: 0.5276 - val_loss: -70.8879\n",
      "Epoch 65/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: -48.4636 - val_accuracy: 0.5276 - val_loss: -74.5089\n",
      "Epoch 66/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: -53.8665 - val_accuracy: 0.5276 - val_loss: -78.5204\n",
      "Epoch 67/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5418 - loss: -53.1996 - val_accuracy: 0.5276 - val_loss: -82.1970\n",
      "Epoch 68/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5806 - loss: -56.1509 - val_accuracy: 0.5276 - val_loss: -85.7955\n",
      "Epoch 69/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5369 - loss: -63.4986 - val_accuracy: 0.5276 - val_loss: -90.0992\n",
      "Epoch 70/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5485 - loss: -56.4294 - val_accuracy: 0.5276 - val_loss: -93.6817\n",
      "Epoch 71/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5649 - loss: -69.5149 - val_accuracy: 0.5276 - val_loss: -98.0532\n",
      "Epoch 72/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5605 - loss: -55.4276 - val_accuracy: 0.5276 - val_loss: -102.0234\n",
      "Epoch 73/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5673 - loss: -61.5340 - val_accuracy: 0.5276 - val_loss: -106.2068\n",
      "Epoch 74/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5500 - loss: -72.5044 - val_accuracy: 0.5276 - val_loss: -110.6509\n",
      "Epoch 75/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5642 - loss: -74.3482 - val_accuracy: 0.5276 - val_loss: -115.2447\n",
      "Epoch 76/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5528 - loss: -77.0656 - val_accuracy: 0.5276 - val_loss: -119.4780\n",
      "Epoch 77/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5391 - loss: -89.7467 - val_accuracy: 0.5276 - val_loss: -124.3735\n",
      "Epoch 78/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5168 - loss: -75.8047 - val_accuracy: 0.5276 - val_loss: -129.0033\n",
      "Epoch 79/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5621 - loss: -85.2706 - val_accuracy: 0.5276 - val_loss: -133.8688\n",
      "Epoch 80/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: -105.1376 - val_accuracy: 0.5276 - val_loss: -138.9386\n",
      "Epoch 81/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5571 - loss: -105.2567 - val_accuracy: 0.5276 - val_loss: -144.3869\n",
      "Epoch 82/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5406 - loss: -90.4577 - val_accuracy: 0.5276 - val_loss: -149.3284\n",
      "Epoch 83/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5577 - loss: -124.3544 - val_accuracy: 0.5276 - val_loss: -154.8940\n",
      "Epoch 84/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5403 - loss: -108.6965 - val_accuracy: 0.5276 - val_loss: -159.8469\n",
      "Epoch 85/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: -114.9803 - val_accuracy: 0.5276 - val_loss: -165.0501\n",
      "Epoch 86/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5547 - loss: -124.1603 - val_accuracy: 0.5276 - val_loss: -170.0930\n",
      "Epoch 87/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5698 - loss: -129.0516 - val_accuracy: 0.5276 - val_loss: -175.4678\n",
      "Epoch 88/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5663 - loss: -115.9383 - val_accuracy: 0.5276 - val_loss: -181.2435\n",
      "Epoch 89/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5849 - loss: -109.6199 - val_accuracy: 0.5276 - val_loss: -187.3398\n",
      "Epoch 90/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5697 - loss: -117.6486 - val_accuracy: 0.5276 - val_loss: -193.3007\n",
      "Epoch 91/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5504 - loss: -132.9921 - val_accuracy: 0.5276 - val_loss: -199.8723\n",
      "Epoch 92/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5688 - loss: -137.2246 - val_accuracy: 0.5276 - val_loss: -206.1501\n",
      "Epoch 93/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5474 - loss: -152.2328 - val_accuracy: 0.5276 - val_loss: -212.9891\n",
      "Epoch 94/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5804 - loss: -125.3452 - val_accuracy: 0.5276 - val_loss: -218.8598\n",
      "Epoch 95/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5589 - loss: -155.6110 - val_accuracy: 0.5276 - val_loss: -226.3574\n",
      "Epoch 96/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5354 - loss: -152.8266 - val_accuracy: 0.5276 - val_loss: -232.7833\n",
      "Epoch 97/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5386 - loss: -160.7242 - val_accuracy: 0.5276 - val_loss: -239.5002\n",
      "Epoch 98/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5602 - loss: -174.0246 - val_accuracy: 0.5276 - val_loss: -246.3925\n",
      "Epoch 99/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5692 - loss: -156.3931 - val_accuracy: 0.5276 - val_loss: -253.6335\n",
      "Epoch 100/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5532 - loss: -185.2611 - val_accuracy: 0.5276 - val_loss: -261.3147\n",
      "Epoch 101/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5420 - loss: -175.4657 - val_accuracy: 0.5276 - val_loss: -268.8604\n",
      "Epoch 102/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5603 - loss: -214.5369 - val_accuracy: 0.5276 - val_loss: -276.7582\n",
      "Epoch 103/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5534 - loss: -194.5527 - val_accuracy: 0.5276 - val_loss: -283.9740\n",
      "Epoch 104/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5516 - loss: -215.0254 - val_accuracy: 0.5276 - val_loss: -291.1261\n",
      "Epoch 105/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5589 - loss: -189.2691 - val_accuracy: 0.5276 - val_loss: -298.8783\n",
      "Epoch 106/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5529 - loss: -187.3069 - val_accuracy: 0.5215 - val_loss: -306.4167\n",
      "Epoch 107/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5331 - loss: -216.9812 - val_accuracy: 0.5215 - val_loss: -314.7338\n",
      "Epoch 108/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5173 - loss: -208.3392 - val_accuracy: 0.5215 - val_loss: -322.9448\n",
      "Epoch 109/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: -186.5753 - val_accuracy: 0.5215 - val_loss: -331.3313\n",
      "Epoch 110/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5297 - loss: -227.0249 - val_accuracy: 0.5215 - val_loss: -340.1774\n",
      "Epoch 111/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5505 - loss: -204.2772 - val_accuracy: 0.5215 - val_loss: -348.1139\n",
      "Epoch 112/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5499 - loss: -255.1628 - val_accuracy: 0.5215 - val_loss: -357.0069\n",
      "Epoch 113/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5935 - loss: -237.5974 - val_accuracy: 0.5215 - val_loss: -365.7214\n",
      "Epoch 114/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5407 - loss: -218.5770 - val_accuracy: 0.5215 - val_loss: -374.5684\n",
      "Epoch 115/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5544 - loss: -265.9456 - val_accuracy: 0.5215 - val_loss: -384.3416\n",
      "Epoch 116/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5637 - loss: -305.6662 - val_accuracy: 0.5215 - val_loss: -393.9713\n",
      "Epoch 117/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5452 - loss: -290.5048 - val_accuracy: 0.5215 - val_loss: -402.9089\n",
      "Epoch 118/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5658 - loss: -268.6176 - val_accuracy: 0.5215 - val_loss: -411.4320\n",
      "Epoch 119/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5456 - loss: -268.3856 - val_accuracy: 0.5215 - val_loss: -420.6704\n",
      "Epoch 120/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5238 - loss: -267.8734 - val_accuracy: 0.5215 - val_loss: -429.9688\n",
      "Epoch 121/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: -315.5700 - val_accuracy: 0.5215 - val_loss: -440.4530\n",
      "Epoch 122/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5248 - loss: -317.8918 - val_accuracy: 0.5215 - val_loss: -450.4777\n",
      "Epoch 123/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5702 - loss: -293.9106 - val_accuracy: 0.5215 - val_loss: -460.6418\n",
      "Epoch 124/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5342 - loss: -377.0593 - val_accuracy: 0.5215 - val_loss: -471.1056\n",
      "Epoch 125/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: -297.6562 - val_accuracy: 0.5215 - val_loss: -480.4371\n",
      "Epoch 126/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5360 - loss: -307.9164 - val_accuracy: 0.5215 - val_loss: -491.2932\n",
      "Epoch 127/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5864 - loss: -330.9113 - val_accuracy: 0.5153 - val_loss: -502.9623\n",
      "Epoch 128/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5351 - loss: -365.5718 - val_accuracy: 0.5153 - val_loss: -513.9095\n",
      "Epoch 129/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5711 - loss: -354.3695 - val_accuracy: 0.5153 - val_loss: -524.5224\n",
      "Epoch 130/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5435 - loss: -342.0012 - val_accuracy: 0.5153 - val_loss: -535.5209\n",
      "Epoch 131/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5459 - loss: -396.0428 - val_accuracy: 0.5153 - val_loss: -545.6240\n",
      "Epoch 132/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5704 - loss: -378.1031 - val_accuracy: 0.5153 - val_loss: -556.7218\n",
      "Epoch 133/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5201 - loss: -379.1575 - val_accuracy: 0.5153 - val_loss: -568.0635\n",
      "Epoch 134/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5575 - loss: -390.9885 - val_accuracy: 0.5153 - val_loss: -579.5695\n",
      "Epoch 135/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5378 - loss: -425.2229 - val_accuracy: 0.5153 - val_loss: -591.8161\n",
      "Epoch 136/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5430 - loss: -440.9961 - val_accuracy: 0.5153 - val_loss: -603.3423\n",
      "Epoch 137/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5387 - loss: -398.3690 - val_accuracy: 0.5153 - val_loss: -614.8427\n",
      "Epoch 138/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5314 - loss: -428.0112 - val_accuracy: 0.5153 - val_loss: -627.4099\n",
      "Epoch 139/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5110 - loss: -490.8584 - val_accuracy: 0.5153 - val_loss: -640.0495\n",
      "Epoch 140/140\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5286 - loss: -501.5068 - val_accuracy: 0.5153 - val_loss: -651.7453\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=140, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca292f9e",
   "metadata": {},
   "source": [
    "Certainly! This line of code is typically used in the context of training a machine learning model with the Keras API in TensorFlow, a popular deep learning library. The code snippet you provided is executing the fit method on a model object, which trains the model on the provided dataset. Here's a breakdown of each component in that line:\n",
    "\n",
    "model.fit(...): This is the method call that trains the model. The model variable is an instance of a neural network or any model built using Keras. The fit method adjusts the model's weights to minimize the loss function, improving the model's performance on the training data.\n",
    "\n",
    "X_train_scaled: This represents the input features for training the model, which have been scaled. Scaling input features is a common practice in machine learning to help the model learn more effectively. It ensures that the feature values are within a similar range, often leading to better performance.\n",
    "\n",
    "y_train: This is the target data for the training set, which the model will try to predict. The y_train data contains the known outputs associated with each input vector in X_train_scaled.\n",
    "\n",
    "epochs=140: An epoch is one complete pass through the entire training dataset. This parameter specifies that the model should be trained for 140 epochs, meaning the learning algorithm will work its way through the training dataset 140 times.\n",
    "\n",
    "batch_size=32: This defines the number of samples that will be propagated through the network before the model's internal parameters are updated. In this case, the model weights are updated after every 32 samples are processed, which is a balance between the efficiency of batch processing and the fine-grained update approach of stochastic gradient descent.\n",
    "\n",
    "validation_split=0.2: This parameter indicates that 20% of the training data should be held back and not used for training the model. Instead, this subset is used as a validation dataset to evaluate the model's performance after each epoch. This helps in monitoring the model's generalization ability to new, unseen data and in preventing overfitting.\n",
    "\n",
    "verbose=1: This is a verbosity mode flag. Setting verbose=1 means that progress bars and one line per epoch will be displayed during the training process. It's a way to get real-time feedback on the training process, including the loss and any other metrics specified in the model compilation.\n",
    "\n",
    "In summary, this code trains a neural network (or any model created with Keras) on the scaled training data (X_train_scaled, y_train), for 140 iterations over the entire dataset, updating the model weights after every 32 samples, while also evaluating model performance on a validation set that comprises 20% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebbd7f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5199 - loss: -608.2734 \n",
      "Test set accuracy: 0.5074\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test set accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce200e",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Model Evaluation: The model.evaluate() function tests the model on a separate dataset that it hasn't seen before, known as the test set (X_test_scaled, y_test). This function returns the loss value & metrics values for the model in test mode. In this case, since the model was compiled with accuracy as a metric, it returns both the loss (loss) and accuracy (accuracy).\n",
    "\n",
    "Parameters:\n",
    "\n",
    "X_test_scaled: The input features of the test set, which have been scaled in the same way as the training set features to ensure consistency in data representation.\n",
    "y_test: The true labels of the test set, used to evaluate the model's predictions.\n",
    "Printing Accuracy: The accuracy metric, which indicates the proportion of correct predictions out of all predictions made, is printed out formatted to four decimal places. Accuracy is a common metric for classification tasks and provides a quick sense of how well the model is performing. An accuracy of 1.0 means the model made correct predictions for every sample in the test set, while an accuracy closer to 0.0 means the model did not perform well.\n",
    "\n",
    "This step is crucial for understanding the model's generalization capability, i.e., how well it performs on new, unseen data. High accuracy on the test set suggests that the model has learned the underlying patterns in the data rather than memorizing the training set, while low accuracy might indicate overfitting to the training data or underfitting, where the model is too simple to capture the data's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bc63e",
   "metadata": {},
   "source": [
    "- Training Phase Output (Epoch Feedback)\n",
    "7/7 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step: This portion indicates the progress of the last batch of the training or evaluation process. Specifically:\n",
    "\n",
    "7/7 means that all 7 batches have been processed. The first number changes as each batch is processed until it matches the total number of batches, which is the second number.\n",
    "0s indicates the total time taken to process these batches was less than one second.\n",
    "5ms/step suggests that, on average, each batch took 5 milliseconds to process.\n",
    "accuracy: 0.5199: This is the accuracy of the model on the training set (or possibly the validation set, if this is during training with validation_split specified). Accuracy measures the proportion of correctly predicted instances out of all predictions made. Here, the model's accuracy is approximately 52%, indicating that about half of the model's predictions match the actual data labels.\n",
    "\n",
    "loss: -608.2734: The loss function value quantifies how well the model's predictions match the actual labels, with lower values generally indicating better performance. However, a negative loss value, as shown here, is unusual for most loss functions and might indicate an issue with how the loss is calculated or with the model's configuration.\n",
    "\n",
    "Test Set Evaluation Output\n",
    "Test set accuracy: 0.5074: This value represents the model's accuracy evaluated on a separate test dataset that was not used during training. An accuracy of approximately 50.74% on the test set suggests that the model performs similarly on both unseen data and the training/validation data, predicting correctly a little over half of the time. This level of accuracy, similar to the training accuracy, indicates consistency but also suggests the model might not be highly effective for its intended task, depending on the complexity of the problem and the baseline accuracy (e.g., what accuracy a naive model might achieve).\n",
    "Interpretation\n",
    "Given the context:\n",
    "\n",
    "An accuracy around 50% might be adequate for tasks akin to flipping a coin (binary outcomes with equal probability), but it's generally low for most machine learning tasks, suggesting the model might not have learned meaningful patterns from the data.\n",
    "A negative loss value is unusual and might hint at an incorrect implementation of the loss function or an issue with the model setup. It's crucial to review the chosen loss function and ensure it aligns with the goals of the model and the nature of the problem being solved.\n",
    "In summary, while the model demonstrates a consistent ability to predict correctly about half of the time across both training and test sets, the performance is not particularly high, and the negative loss value indicates a potential issue needing investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "813f8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da2900e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Prediction: [[1.1180724e-16]]\n"
     ]
    }
   ],
   "source": [
    "# making a prediction\n",
    "new_data = np.array([[42, 140, 85, 13, 98, 75]])  # Replace with actual values\n",
    "new_data_scaled = scaler.transform(new_data)  # This should work if 'scaler' is defined and fitted correctly\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(f'Prediction: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3d4de",
   "metadata": {},
   "source": [
    "- Explanation\n",
    "This block of code demonstrates how to make a prediction using the trained neural network model for a new, unseen piece of data.\n",
    "\n",
    "Prepare New Data: new_data is an np.array that contains a new data point. Each number in the array represents a feature's value. In this context, the features could represent different measurements or characteristics relevant to the model (e.g., age, systolic blood pressure, diastolic blood pressure, blood sugar, body temperature, heart rate). The specific values here (45, 150, 85, 13, 98, 75) are placeholders and should be replaced with actual values of the features for which you want to make a prediction.\n",
    "\n",
    "Normalize New Data: The new data is then normalized using the scaler that was fitted on the training data. This step is crucial because the model expects data in the same format it was trained on, including the same scale. Normalization (or scaling) ensures that the input features have the same scale as the training data, which helps the model make accurate predictions.\n",
    "\n",
    "Make a Prediction: The normalized new data is passed to the model.predict() method, which returns the model's prediction for the data. Since this is a classification model, the output will be the model's confidence levels for the different classes it was trained to predict.\n",
    "\n",
    "Print Prediction: Finally, the prediction made by the model is printed. The output format will depend on the model's final layer and activation function. For binary classification problems using a sigmoid activation function in the output layer, this will typically be a probability score between 0 and 1, indicating the likelihood of the sample belonging to the positive class.\n",
    "\n",
    "This example is essential for applying the model to real-world data, allowing you to understand how the model interprets and predicts based on new inputs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46ab7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 KB\u001b[0m \u001b[31m491.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from keras-tuner) (21.3)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: keras in /home/hduser/.local/lib/python3.10/site-packages (from keras-tuner) (3.1.1)\n",
      "Requirement already satisfied: requests in /home/hduser/.local/lib/python3.10/site-packages (from keras-tuner) (2.28.1)\n",
      "Requirement already satisfied: absl-py in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: h5py in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: rich in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: numpy in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (1.24.0)\n",
      "Requirement already satisfied: optree in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: namex in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: ml-dtypes in /home/hduser/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/hduser/.local/lib/python3.10/site-packages (from requests->keras-tuner) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from optree->keras->keras-tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/hduser/.local/lib/python3.10/site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/hduser/.local/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/hduser/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3a123",
   "metadata": {},
   "source": [
    "### Tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f8a29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('units_input', min_value=32, max_value=512, step=32), activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(hp.Int('units_hidden', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Adjusting the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457c9cf",
   "metadata": {},
   "source": [
    "This code snippet is for defining a function that builds a neural network model with customizable hyperparameters, intended for use with a hyperparameter tuning process. The build_model function takes a hp argument, which allows specifying hyperparameter ranges for the model's architecture and compilation settings, such as the number of units in the layers and the learning rate for the Adam optimizer. The model is compiled with binary crossentropy loss, making it suitable for binary classification tasks, and uses accuracy as a metric to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fdfe9f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_results/keras_tuner_demo/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Maximum number of hyperparameter combinations to test\n",
    "    executions_per_trial=2,  # Number of models to train and evaluate for each trial\n",
    "    directory='tuner_results',\n",
    "    project_name='keras_tuner_demo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f10972",
   "metadata": {},
   "source": [
    "- RandomSearch tuner from Keras Tuner, setting up a hyperparameter tuning session for the model defined by the build model function. The tuner aims to optimize the validation accuracy  of the models it tests. It will experiment with up to 10 different hyperparameter combinations, training and evaluating 2 models for each trial to average out the performance metrics. The results of the tuning process, including the performance of each trial and the best hyperparameter settings found, will be stored in the tuner results directory under a project named keras tuner demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b73a9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389f198",
   "metadata": {},
   "source": [
    "tuner.search(...): This method initiates the searching (tuning) process for the best hyperparameters for your model. The tuner object here has been previously set up with specific configurations such as the model-building function, the number of trials, and the objective metric to optimize.\n",
    "\n",
    "X_train_scaled: This is the scaled training data that you're passing to the tuner. Scaling is a preprocessing step that is critical for many machine learning algorithms to perform well, especially neural networks. It involves transforming numerical features to have a certain range, such as between 0 and 1, to help the algorithm converge more quickly.\n",
    "\n",
    "y_train: These are the target values (labels) for the training data. In the context of supervised learning, the model learns to predict these values from the X_train_scaled data.\n",
    "\n",
    "epochs=20: This parameter specifies the number of times the learning algorithm will work through the entire training dataset. An epoch is one forward pass and one backward pass of all the training examples. In this case, the tuner will train each model configuration it tests for 20 epochs.\n",
    "\n",
    "validation_split=0.2: This indicates that 20% of the training data should be set aside and not used for training the model. Instead, this data will be used to evaluate the model's performance. This helps in monitoring how well the model is generalizing to unseen data and can aid in preventing overfitting.\n",
    "\n",
    "verbose=1: This is a verbosity mode setting. Setting verbose=1 will display detailed progress logs of the training process, including the loss and accuracy for each epoch. It provides a way to visually monitor the model's training progress.\n",
    "\n",
    "In summary, this line instructs the tuner to start the hyperparameter tuning process. It will train and evaluate models using different combinations of hyperparameters specified in your build_model function, using the provided training data and settings. The process aims to find the set of hyperparameters that results in the model achieving the best performance according to the objective, in this case, validation accuracy (val_accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142b2c3",
   "metadata": {},
   "source": [
    "#### Retrieving and evaluate the best model found by the hyperparameter tuning process using Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e57af85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5408 - loss: -95933.4375  \n",
      "Test set accuracy of the best model: 0.5320\n",
      "Best hyperparameters: {'units_input': 64, 'units_hidden': 448, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameter\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Evaluating the best model\n",
    "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test set accuracy of the best model: {accuracy:.4f}')\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc43cb",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "accuracy: 0.5408: This is the accuracy of the best model on the validation set during the final epoch of training, indicating that the model correctly predicts 54.08% of the validation set. While better than random guessing in binary classification, this accuracy might still be considered low for many practical applications, depending on the specific problem and the baseline accuracy.\n",
    "\n",
    "loss: -95933.4375: The negative loss value is highly unusual in the context of most problems, including binary classification with a binary crossentropy loss function. Typically, loss values are positive, and a negative value could indicate an issue with the loss function calculation, model configuration, or data. It warrants a thorough investigation.\n",
    "\n",
    "Test Set Performance\n",
    "Test set accuracy of the best model: 0.5320: The best model achieves an accuracy of 53.20% on the test set. This performance is close to its validation accuracy, indicating consistency in how the model generalizes to unseen data. However, the effectiveness of the model in practical terms may be limited due to the relatively low accuracy rate.\n",
    "Best Hyperparameters\n",
    "{'units_input': 64, 'units_hidden': 448, 'learning_rate': 0.01}: These are the hyperparameters of the best-performing model found by the tuner.\n",
    "units_input: 64: The first (input) layer of the model consists of 64 units (neurons). This parameter controls the dimensionality of the first hidden layer's output space.\n",
    "units_hidden: 448: The second hidden layer has 448 units. This is a relatively large number, suggesting that the model might be trying to capture complex patterns in the data.\n",
    "learning_rate: 0.01: The learning rate for the Adam optimizer is set to 0.01. This is a crucial hyperparameter that controls the size of the steps the optimizer takes during the gradient descent process. A learning rate of 0.01 is relatively standard, balancing the speed of convergence with the risk of overshooting the minimum of the loss function.\n",
    "Overall Implications\n",
    "The results suggest that while the hyperparameter tuning process identified a specific model configuration as the best, the overall performance on the validation and test sets remains modest. The accuracy levels achieved suggest the model has limited predictive power, which might be insufficient for many applications. Moreover, the negative loss value indicates a potential issue that needs addressing.\n",
    "\n",
    "It's advisable to review the model configuration, the data preprocessing steps, and the loss function implementation. Additionally, experimenting with different model architectures, loss functions, or even reevaluating the problem formulation and the data could provide pathways to improved performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293d3c4",
   "metadata": {},
   "source": [
    "### LTM Feedforward RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e63ce86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Index the label if it's categorical\n",
    "indexer = StringIndexer(inputCol=\"RiskLevel\", outputCol=\"label\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Assemble features into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"Age\", \"SystolicBP\", \"DiastolicBP\", \"BS\", \"BodyTemp\", \"HeartRate\"], outputCol=\"features\")\n",
    "data = assembler.transform(df)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5572dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Defining the neural network architecture\n",
    "# The number of nodes in the input layer must match the number of features, and the number of nodes in the output layer must match the number of classes.\n",
    "# In this example, we'll assume 3 classes (risks) and 6 features.\n",
    "layers = [6, 5, 4, 3]\n",
    "\n",
    "# Creating the classifier\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, blockSize=128, seed=1234, maxIter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e1b68",
   "metadata": {},
   "source": [
    "-This code snippet is for setting up a Multilayer Perceptron (MLP) Classifier in PySpark, which is a type of neural network used for classification tasks. Here's what each part does in English:\n",
    "\n",
    "Importing the MLP Classifier: The first line imports the MultilayerPerceptronClassifier class from Spark's machine learning library (MLlib). This class is used to create and train the MLP model.\n",
    "\n",
    "Defining the Network Architecture: The layers array defines the architecture of the neural network. The number of nodes (neurons) in the input layer is 6, matching the number of features in the dataset. The network includes two hidden layers with 5 and 4 nodes, respectively, and the output layer has 3 nodes, corresponding to the 3 classes (risk levels). The structure of a network is crucial as it can significantly influence the model's performance.\n",
    "\n",
    "Creating the Classifier: An instance of the MultilayerPerceptronClassifier is created with the specified layers. Additionally:\n",
    "\n",
    "blockSize=128 specifies the size of blocks to be used for stacking input data in matrices to speed up the computation. Increasing the block size can utilize the computational power more efficiently at the cost of higher memory consumption.\n",
    "seed=1234 is used to initialize the random number generator, ensuring that the results of the model training are reproducible.\n",
    "maxIter=100 sets the maximum number of iterations (epochs) over the dataset for which the algorithm will run. If the algorithm converges (i.e., improvements become negligibly small) before reaching this limit, the training will stop early.\n",
    "This setup is part of the process for preparing to train a neural network model on a dataset with 6 features to predict one of 3 possible risk levels. The use of an MLP in Spark allows for scalable and distributed computing over large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2292970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model = mlp.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c419ad",
   "metadata": {},
   "source": [
    "This line of code initiates the training process of the Multilayer Perceptron (MLP) classifier on the train_data. During training, the MLP will learn to classify input data into the predefined classes by adjusting its weights based on the input features and corresponding labels in the training dataset. This process iterates over the specified number of epochs or until convergence, as defined in the MLP configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "54987772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5225806451612903\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluating accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a7c3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Making sure the 'label' column does not cause conflict\n",
    "if \"label\" in df.columns:\n",
    "    df = df.drop(\"label\")\n",
    "\n",
    "# Indexing categorical labels with a new column name to avoid conflicts\n",
    "indexer = StringIndexer(inputCol=\"RiskLevel\", outputCol=\"indexedLabel\").fit(df)\n",
    "df_indexed = indexer.transform(df)\n",
    "\n",
    "# Assembling the features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Age\", \"SystolicBP\", \"DiastolicBP\", \"BS\", \"BodyTemp\", \"HeartRate\"],\n",
    "    outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df_indexed)\n",
    "\n",
    "# Normalizing the features (optional but recommended)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(df_assembled)\n",
    "df_scaled = scalerModel.transform(df_assembled)\n",
    "\n",
    "# Splitting the data\n",
    "(train_data, test_data) = df_scaled.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72d670",
   "metadata": {},
   "source": [
    "This code block is part of a data preprocessing routine for a machine learning pipeline using PySpark's MLlib. Let's translate it into English and then explain its purpose and function:\n",
    "\n",
    "Explanation\n",
    "Avoiding Column Conflict: First, the code checks if a column named label already exists in the DataFrame df and drops it if found. This is to avoid conflicts with many machine learning algorithms that expect a column named label to be the target variable.\n",
    "\n",
    "Indexing Categorical Labels: StringIndexer is used to convert the categorical labels in the RiskLevel column into numerical indices. This process is necessary because most machine learning models work with numerical data. The new indices are stored in a column named indexedLabel.\n",
    "\n",
    "Assembling Features: VectorAssembler combines multiple columns (in this case, various features like Age, SystolicBP, etc.) into a single vector column named features. This step is required because Spark ML algorithms expect input data to be in this format.\n",
    "\n",
    "Normalizing Features: StandardScaler standardizes the features by scaling them to have a mean of 0 and a standard deviation of 1. This step, while optional, is often recommended as it can improve the performance of many machine learning algorithms. The scaled features are stored in a new column named scaledFeatures.\n",
    "\n",
    "Splitting the Data: Finally, the processed DataFrame is randomly split into training and test datasets, with 80% of the data going to the training set and the remaining 20% to the test set. This is a common practice in machine learning to evaluate the model's performance on unseen data.\n",
    "\n",
    "Purpose\n",
    "The entire process prepares the data for training a machine learning model by ensuring that the data is in the correct format, categorical labels are appropriately indexed, features are standardized, and the dataset is divided into training and testing sets. This preparation is crucial for the success of many machine learning tasks, including classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e997bc0",
   "metadata": {},
   "source": [
    "- building, training, and evaluating a Multilayer Perceptron (MLP) classifier using PySpark's MLlib for a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3f4c4c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5751\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Defining the network architecture: number of nodes in the input layer equals the number of features; adjust as necessary\n",
    "layers = [6, 5, 4, 3]  # Example: 6 input features, two hidden layers (5 and 4 neurons), 3 outputs\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    layers=layers,\n",
    "    blockSize=128,\n",
    "    seed=1234,\n",
    "    maxIter=100,\n",
    "    featuresCol=\"scaledFeatures\",\n",
    "    labelCol=\"indexedLabel\")  # Adjust to use the 'indexedLabel' column\n",
    "\n",
    "# Training the model\n",
    "model = mlp.fit(train_data)\n",
    "\n",
    "# Model evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9899b4",
   "metadata": {},
   "source": [
    "Neste exemplo, build_model é uma função que constrói um modelo Keras. Ela usa o objeto hp (de hiperparâmetros) do keras-tuner para explorar diferentes valores de unidades na camada oculta, taxas de aprendizado e otimizadores. O keras-tuner então busca no espaço de hiperparâmetros fornecido para encontrar a melhor combinação de acordo com a acurácia de validação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
